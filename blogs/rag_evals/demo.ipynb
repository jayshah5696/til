{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Download pdfs\n",
    "https://maint.loc.gov/law/help/artificial-intelligence/regulation-artificial-intelligence.pdf\n",
    "\n",
    "read this pdf to text using pymupdf4llm\n",
    "\n",
    "using instructor and google ai studio models, generate document and question pairs\n",
    "1. simple per page questions\n",
    "2. complex questions based on a few pages\n",
    "\n",
    "Now evaluete this on lance db with \n",
    "fts\n",
    "vector\n",
    "hybrid\n",
    "fts+ reranker\n",
    "vector + reranker\n",
    "hybrid + reranker\n",
    "following with ragatouille\n",
    "colbert -small\n",
    "colbert jina \n",
    "\n",
    "metrics to evaluate\n",
    "1. mrr\n",
    "2. ndcg\n",
    "3. recall @k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from litellm import completion\n",
    "import json\n",
    "from rich.pretty import pprint\n",
    "from tqdm import tqdm\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "\n",
    "from pymupdf import Document as FitzDocument\n",
    "\n",
    "from pymupdf4llm import IdentifyHeaders, to_markdown\n",
    "import pymupdf\n",
    "import lancedb\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry, OpenAIEmbeddings\n",
    "import os\n",
    "import requests\n",
    "import tenacity\n",
    "import time\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def process_pdf(pdf_path,additional_info=None):\n",
    "    \"\"\"\n",
    "    This function processes a PDF file and extracts markdown text and metadata for each page.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the PDF file.\n",
    "        additional_info (dict, optional): Additional metadata to include in the output. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two dictionaries:\n",
    "            - pymupdf_markdown_by_page: A dictionary mapping page numbers to their markdown text.\n",
    "            - pymupdf_metadata_by_page: A dictionary mapping page numbers to their metadata.\n",
    "    \"\"\"\n",
    "    hdr_info = IdentifyHeaders(pdf_path)\n",
    "    # print(hdr_info)\n",
    "    doc: FitzDocument = pymupdf.open(pdf_path)\n",
    "    pymupdf_markdown_by_page = {}\n",
    "    pymupdf_metadata_by_page = {}\n",
    "\n",
    "    for page in tqdm(doc, desc=\"Processing pages\"):\n",
    "        extra_info = {}\n",
    "        extra_info.update(doc.metadata)\n",
    "        extra_info[\"page\"] = page.number + 1\n",
    "        extra_info[\"total_pages\"] = len(doc)\n",
    "        extra_info[\"file_path\"] = str(pdf_path)\n",
    "        if additional_info:\n",
    "            extra_info.update(additional_info)\n",
    "        text = to_markdown(\n",
    "                doc, pages=[page.number], hdr_info=hdr_info, write_images=False\n",
    "            )\n",
    "        pymupdf_markdown_by_page[page.number] = text\n",
    "        pymupdf_metadata_by_page[page.number] = json.dumps(extra_info)\n",
    "    return pymupdf_markdown_by_page, pymupdf_metadata_by_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PDF from https://maint.loc.gov/law/help/artificial-intelligence/regulation-artificial-intelligence.pdf...\n",
      "Downloaded PDF to /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:   0%|          | 0/138 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:   2%|▏         | 3/138 [00:00<00:04, 29.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:   4%|▍         | 6/138 [00:00<00:07, 17.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:   7%|▋         | 9/138 [00:00<00:06, 20.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:   9%|▊         | 12/138 [00:00<00:06, 18.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  11%|█         | 15/138 [00:01<00:12,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  12%|█▏        | 17/138 [00:01<00:15,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  14%|█▍        | 19/138 [00:02<00:18,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  15%|█▌        | 21/138 [00:02<00:15,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  17%|█▋        | 23/138 [00:02<00:16,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  17%|█▋        | 24/138 [00:02<00:17,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  18%|█▊        | 25/138 [00:02<00:19,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  19%|█▉        | 26/138 [00:03<00:23,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  20%|█▉        | 27/138 [00:03<00:22,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  20%|██        | 28/138 [00:03<00:22,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  21%|██        | 29/138 [00:03<00:22,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  22%|██▏       | 30/138 [00:04<00:19,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  22%|██▏       | 31/138 [00:04<00:17,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  24%|██▍       | 33/138 [00:04<00:13,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  25%|██▍       | 34/138 [00:04<00:15,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  25%|██▌       | 35/138 [00:04<00:19,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  26%|██▌       | 36/138 [00:05<00:20,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  27%|██▋       | 37/138 [00:05<00:25,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  28%|██▊       | 38/138 [00:05<00:30,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  28%|██▊       | 39/138 [00:06<00:30,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  29%|██▉       | 40/138 [00:06<00:25,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  30%|██▉       | 41/138 [00:06<00:22,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  30%|███       | 42/138 [00:06<00:19,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  31%|███       | 43/138 [00:06<00:17,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  33%|███▎      | 45/138 [00:07<00:14,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  33%|███▎      | 46/138 [00:07<00:16,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  34%|███▍      | 47/138 [00:07<00:17,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  35%|███▍      | 48/138 [00:07<00:16,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  36%|███▌      | 49/138 [00:07<00:14,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  36%|███▌      | 50/138 [00:08<00:17,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  37%|███▋      | 51/138 [00:08<00:15,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  38%|███▊      | 52/138 [00:08<00:15,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  38%|███▊      | 53/138 [00:08<00:20,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  39%|███▉      | 54/138 [00:09<00:19,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  40%|███▉      | 55/138 [00:09<00:20,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  41%|████      | 56/138 [00:09<00:21,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  41%|████▏     | 57/138 [00:09<00:20,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  42%|████▏     | 58/138 [00:10<00:21,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  43%|████▎     | 59/138 [00:10<00:19,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  43%|████▎     | 60/138 [00:10<00:17,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  44%|████▍     | 61/138 [00:10<00:17,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  45%|████▍     | 62/138 [00:10<00:14,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  46%|████▌     | 63/138 [00:10<00:12,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  46%|████▋     | 64/138 [00:11<00:11,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  47%|████▋     | 65/138 [00:11<00:10,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  48%|████▊     | 66/138 [00:11<00:12,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  49%|████▊     | 67/138 [00:11<00:12,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  50%|█████     | 69/138 [00:11<00:10,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  51%|█████     | 70/138 [00:12<00:11,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  51%|█████▏    | 71/138 [00:12<00:11,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  52%|█████▏    | 72/138 [00:12<00:11,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  53%|█████▎    | 73/138 [00:12<00:12,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  54%|█████▎    | 74/138 [00:12<00:13,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  54%|█████▍    | 75/138 [00:13<00:14,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  55%|█████▌    | 76/138 [00:13<00:12,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  56%|█████▌    | 77/138 [00:13<00:11,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  57%|█████▋    | 78/138 [00:13<00:12,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  57%|█████▋    | 79/138 [00:14<00:13,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  58%|█████▊    | 80/138 [00:14<00:11,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  59%|█████▊    | 81/138 [00:14<00:15,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  59%|█████▉    | 82/138 [00:14<00:13,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  61%|██████    | 84/138 [00:15<00:11,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  62%|██████▏   | 85/138 [00:15<00:11,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  62%|██████▏   | 86/138 [00:15<00:11,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  64%|██████▍   | 88/138 [00:16<00:10,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  64%|██████▍   | 89/138 [00:16<00:12,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  65%|██████▌   | 90/138 [00:16<00:12,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  66%|██████▌   | 91/138 [00:16<00:12,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  67%|██████▋   | 92/138 [00:17<00:11,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  67%|██████▋   | 93/138 [00:17<00:11,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  68%|██████▊   | 94/138 [00:17<00:11,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  69%|██████▉   | 95/138 [00:17<00:09,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  70%|██████▉   | 96/138 [00:18<00:08,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  71%|███████   | 98/138 [00:18<00:06,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  72%|███████▏  | 99/138 [00:18<00:06,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  72%|███████▏  | 100/138 [00:18<00:05,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  73%|███████▎  | 101/138 [00:18<00:06,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  74%|███████▍  | 102/138 [00:18<00:05,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  75%|███████▍  | 103/138 [00:19<00:05,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  75%|███████▌  | 104/138 [00:19<00:06,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  76%|███████▌  | 105/138 [00:19<00:06,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  77%|███████▋  | 106/138 [00:19<00:05,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  78%|███████▊  | 107/138 [00:19<00:06,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  78%|███████▊  | 108/138 [00:20<00:05,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  80%|███████▉  | 110/138 [00:20<00:04,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  80%|████████  | 111/138 [00:20<00:04,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  81%|████████  | 112/138 [00:20<00:03,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  82%|████████▏ | 113/138 [00:20<00:03,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  83%|████████▎ | 114/138 [00:20<00:03,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  83%|████████▎ | 115/138 [00:21<00:03,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  84%|████████▍ | 116/138 [00:21<00:04,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  85%|████████▍ | 117/138 [00:21<00:04,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  86%|████████▌ | 118/138 [00:21<00:04,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  86%|████████▌ | 119/138 [00:22<00:04,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  87%|████████▋ | 120/138 [00:22<00:04,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  88%|████████▊ | 121/138 [00:22<00:04,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  88%|████████▊ | 122/138 [00:22<00:04,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  89%|████████▉ | 123/138 [00:23<00:03,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  91%|█████████ | 125/138 [00:23<00:02,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  91%|█████████▏| 126/138 [00:23<00:01,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  93%|█████████▎| 128/138 [00:23<00:01,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  93%|█████████▎| 129/138 [00:23<00:01,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  94%|█████████▍| 130/138 [00:24<00:01,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  95%|█████████▍| 131/138 [00:24<00:01,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  96%|█████████▌| 132/138 [00:24<00:01,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  96%|█████████▋| 133/138 [00:24<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  98%|█████████▊| 135/138 [00:24<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:  99%|█████████▊| 136/138 [00:24<00:00,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing /Users/jshah/Documents/GitHub/til/blogs/rag_evals/downloaded_pdf.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages: 100%|██████████| 138/138 [00:25<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "pdf_url = 'https://maint.loc.gov/law/help/artificial-intelligence/regulation-artificial-intelligence.pdf'  # Replace with the actual link\n",
    "pdf_path = os.path.join(os.getcwd(), 'downloaded_pdf.pdf')  # Define the path where the PDF will be saved\n",
    "\n",
    "# Check if the PDF is already downloaded\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"Downloading PDF from {pdf_url}...\")\n",
    "    response = requests.get(pdf_url)\n",
    "    with open(pdf_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded PDF to {pdf_path}\")\n",
    "else:\n",
    "    print(f\"PDF already exists at {pdf_path}\")\n",
    "\n",
    "# Process the single PDF\n",
    "final_data = []\n",
    "markdown_by_page, metadata_by_page = process_pdf(pdf_path)\n",
    "for page_number, text in markdown_by_page.items():\n",
    "    final_data.append(\n",
    "        {\n",
    "            \"text\": text,\n",
    "            \"metadata\": metadata_by_page[page_number],\n",
    "            \"page_number\": page_number,\n",
    "            \"file_path\": pdf_path,\n",
    "            \"title\": os.path.basename(pdf_path),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ the issue of ‘black box’ algorithms” and is “focused on placing the responsibility on companies to              │\n",
       "│ prevent harm.”[85]                                                                                              │\n",
       "│                                                                                                                 │\n",
       "│ The Committee’s report states that                                                                              │\n",
       "│                                                                                                                 │\n",
       "│ he second group of rights relate to the right to object to automated decision-making and                        │\n",
       "│ to access the logic behind it. In our view, these rights, again a response by the EU to                         │\n",
       "│ emerging challenges from Big Data and AI, have a legitimate rationale. They are aimed at                        │\n",
       "│ curbing harms due to prejudice and discrimination in output data owing to evaluative                            │\n",
       "│ determinations without human review. The solution provided by this right is to simply                           │\n",
       "│ involve a step of human review, which is not per se immune from prejudice. This is a                            │\n",
       "│ change pertaining to the operational structure of an organisation. Such a change may be                         │\n",
       "│ necessitated, provided it is carefully tailored to specific organisations and the nature of                     │\n",
       "│ their processing activity. This, in our view, is better achieved through an accountability                      │\n",
       "│ framework which requires certain data fiduciaries, which may be making evaluative                               │\n",
       "│ decisions through automated means, to set up processes that weed out discrimination. This                       │\n",
       "│ is a constituent element of privacy by design which should be implemented by entities                           │\n",
       "│ proactively, audited periodically and monitored by the DPA in case there are examples of                        │\n",
       "│ unlawful processing. At the same time, such a model does not entirely denude the                                │\n",
       "│ individual of agency. If discrimination has ensued as a result of per se lawful, yet                            │\n",
       "│ discriminatory automated processing, individuals are always at liberty to go to courts for                      │\n",
       "│ breach of fiduciary duties. Thus, the interests underlying such rights, can be more                             │\n",
       "│ efficaciously achieved by an ex ante accountability model.[86]                                                  │\n",
       "│                                                                                                                 │\n",
       "│ **B. Automated Vehicles**                                                                                       │\n",
       "│                                                                                                                 │\n",
       "│ The Seventh Schedule of the Constitution of India lists legislative subjects that are in the exclusive          │\n",
       "│ or concurrent jurisdiction of the central government or state governments. The regulation of motor              │\n",
       "│ vehicles in India appears to be under the concurrent jurisdiction of both the central and state                 │\n",
       "│ governments.[87] Motor vehicle road safety is regulated by the central level by the Motor Vehicles              │\n",
       "│ Act[88] and the Central Motor Vehicle Rules.[89] State governments have their own laws and policies.            │\n",
       "│ The current Motor Vehicle Act does not appear to allow for automated vehicles (AVs) or AV                       │\n",
       "│ testing. However, amending legislation, which was passed in the Lok Sabha (lower house of                       │\n",
       "│ Parliament) on April 10, 2017, but is still pending before the upper house chamber, the Rajya                   │\n",
       "│ Sabha, includes an exemption that may allow testing of AVs:                                                     │\n",
       "│                                                                                                                 │\n",
       "│ 85 _Id._                                                                                                        │\n",
       "│                                                                                                                 │\n",
       "│ 86 COMMITTEE OF EXPERTS UNDER THE CHAIRMANSHIP OF JUSTICE B.N. SRIKRISHNA, _supra note_ at 83, at 74-5.         │\n",
       "│                                                                                                                 │\n",
       "│ 87 Legislative subject no. 35, “Mechanically propelled vehicles,” is on the concurrent list of the Constitution │\n",
       "│ of                                                                                                              │\n",
       "│ [India. (INDIA CONST. Seventh Sched., List III—Concurrent List, Item 35,                                        │\n",
       "│ https://www.india.gov.in/sites/](https://www.india.gov.in/sites/upload_files/npi/files/coi-eng-schedules_1-12.p │\n",
       "│ df)                                                                                                             │\n",
       "│ (https://www.india.gov.in/sites/upload_files/npi/files/coi-eng-schedules_1-12.pdf) (https://perma.cc/7LKA-PXMU) │\n",
       "│                                                                                                                 │\n",
       "│ [88 Motor Vehicles Act, No. 59 of 1988, http://www.tn.gov.in/sta/Mvact1988.pdf, archived                        │\n",
       "│ at](http://www.tn.gov.in/sta/Mvact1988.pdf)                                                                     │\n",
       "│ (https://perma.cc/ZZY9-EZJQ)                                                                                    │\n",
       "│                                                                                                                 │\n",
       "│ [89 Central Motor Vehicles Rules, 1989, http://www.tn.gov.in/sta/Cmvr1989.pdf, archived                         │\n",
       "│ at](http://www.tn.gov.in/sta/Cmvr1989.pdf) (https://perma.cc/X9T3-LP8F)                                         │\n",
       "│ [LP8F.](https://perma.cc/X9T3-LP8F)                                                                             │\n",
       "│                                                                                                                 │\n",
       "│                                                                                                                 │\n",
       "│ -----                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│                                                                                                                 │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ the issue of ‘black box’ algorithms” and is “focused on placing the responsibility on companies to              │\n",
       "│ prevent harm.”[85]                                                                                              │\n",
       "│                                                                                                                 │\n",
       "│ The Committee’s report states that                                                                              │\n",
       "│                                                                                                                 │\n",
       "│ he second group of rights relate to the right to object to automated decision-making and                        │\n",
       "│ to access the logic behind it. In our view, these rights, again a response by the EU to                         │\n",
       "│ emerging challenges from Big Data and AI, have a legitimate rationale. They are aimed at                        │\n",
       "│ curbing harms due to prejudice and discrimination in output data owing to evaluative                            │\n",
       "│ determinations without human review. The solution provided by this right is to simply                           │\n",
       "│ involve a step of human review, which is not per se immune from prejudice. This is a                            │\n",
       "│ change pertaining to the operational structure of an organisation. Such a change may be                         │\n",
       "│ necessitated, provided it is carefully tailored to specific organisations and the nature of                     │\n",
       "│ their processing activity. This, in our view, is better achieved through an accountability                      │\n",
       "│ framework which requires certain data fiduciaries, which may be making evaluative                               │\n",
       "│ decisions through automated means, to set up processes that weed out discrimination. This                       │\n",
       "│ is a constituent element of privacy by design which should be implemented by entities                           │\n",
       "│ proactively, audited periodically and monitored by the DPA in case there are examples of                        │\n",
       "│ unlawful processing. At the same time, such a model does not entirely denude the                                │\n",
       "│ individual of agency. If discrimination has ensued as a result of per se lawful, yet                            │\n",
       "│ discriminatory automated processing, individuals are always at liberty to go to courts for                      │\n",
       "│ breach of fiduciary duties. Thus, the interests underlying such rights, can be more                             │\n",
       "│ efficaciously achieved by an ex ante accountability model.[86]                                                  │\n",
       "│                                                                                                                 │\n",
       "│ **B. Automated Vehicles**                                                                                       │\n",
       "│                                                                                                                 │\n",
       "│ The Seventh Schedule of the Constitution of India lists legislative subjects that are in the exclusive          │\n",
       "│ or concurrent jurisdiction of the central government or state governments. The regulation of motor              │\n",
       "│ vehicles in India appears to be under the concurrent jurisdiction of both the central and state                 │\n",
       "│ governments.[87] Motor vehicle road safety is regulated by the central level by the Motor Vehicles              │\n",
       "│ Act[88] and the Central Motor Vehicle Rules.[89] State governments have their own laws and policies.            │\n",
       "│ The current Motor Vehicle Act does not appear to allow for automated vehicles (AVs) or AV                       │\n",
       "│ testing. However, amending legislation, which was passed in the Lok Sabha (lower house of                       │\n",
       "│ Parliament) on April 10, 2017, but is still pending before the upper house chamber, the Rajya                   │\n",
       "│ Sabha, includes an exemption that may allow testing of AVs:                                                     │\n",
       "│                                                                                                                 │\n",
       "│ 85 _Id._                                                                                                        │\n",
       "│                                                                                                                 │\n",
       "│ 86 COMMITTEE OF EXPERTS UNDER THE CHAIRMANSHIP OF JUSTICE B.N. SRIKRISHNA, _supra note_ at 83, at 74-5.         │\n",
       "│                                                                                                                 │\n",
       "│ 87 Legislative subject no. 35, “Mechanically propelled vehicles,” is on the concurrent list of the Constitution │\n",
       "│ of                                                                                                              │\n",
       "│ [India. (INDIA CONST. Seventh Sched., List III—Concurrent List, Item 35,                                        │\n",
       "│ https://www.india.gov.in/sites/](https://www.india.gov.in/sites/upload_files/npi/files/coi-eng-schedules_1-12.p │\n",
       "│ df)                                                                                                             │\n",
       "│ (https://www.india.gov.in/sites/upload_files/npi/files/coi-eng-schedules_1-12.pdf) (https://perma.cc/7LKA-PXMU) │\n",
       "│                                                                                                                 │\n",
       "│ [88 Motor Vehicles Act, No. 59 of 1988, http://www.tn.gov.in/sta/Mvact1988.pdf, archived                        │\n",
       "│ at](http://www.tn.gov.in/sta/Mvact1988.pdf)                                                                     │\n",
       "│ (https://perma.cc/ZZY9-EZJQ)                                                                                    │\n",
       "│                                                                                                                 │\n",
       "│ [89 Central Motor Vehicles Rules, 1989, http://www.tn.gov.in/sta/Cmvr1989.pdf, archived                         │\n",
       "│ at](http://www.tn.gov.in/sta/Cmvr1989.pdf) (https://perma.cc/X9T3-LP8F)                                         │\n",
       "│ [LP8F.](https://perma.cc/X9T3-LP8F)                                                                             │\n",
       "│                                                                                                                 │\n",
       "│                                                                                                                 │\n",
       "│ -----                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│                                                                                                                 │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing a page \n",
    "\n",
    "console = Console()\n",
    "page_number=50\n",
    "console.print(Panel(markdown_by_page[page_number]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = OpenAIEmbeddings(name='text-embedding-3-small')\n",
    "# Define the LanceModel for your table\n",
    "class Corpus(LanceModel):\n",
    "    text: str = model.SourceField()  \n",
    "    metadata: str = None \n",
    "    page_number: int = None  \n",
    "    title: str = None\n",
    "    vector: Vector(1536) = model.VectorField()\n",
    "\n",
    "# Create the table\n",
    "db = lancedb.connect(\"./.lancedb\")\n",
    "tbl = db.create_table(\"corpus\", schema=Corpus)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.add(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "      <th>page_number</th>\n",
       "      <th>title</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># Regulation of Artificial Intelligence in Sel...</td>\n",
       "      <td>{\"format\": \"PDF 1.6\", \"title\": \"Regulation of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>downloaded_pdf.pdf</td>\n",
       "      <td>[-0.016118292, 0.028076159, 0.04120163, 0.0225...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This report is provided for reference purposes...</td>\n",
       "      <td>{\"format\": \"PDF 1.6\", \"title\": \"Regulation of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>downloaded_pdf.pdf</td>\n",
       "      <td>[0.023184152, 0.033128623, 0.099621244, 0.0307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### Contents\\n\\n**Comparative Summary ...........</td>\n",
       "      <td>{\"format\": \"PDF 1.6\", \"title\": \"Regulation of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>downloaded_pdf.pdf</td>\n",
       "      <td>[-0.033615343, -0.013138391, 0.054029632, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan ..........................................</td>\n",
       "      <td>{\"format\": \"PDF 1.6\", \"title\": \"Regulation of ...</td>\n",
       "      <td>3</td>\n",
       "      <td>downloaded_pdf.pdf</td>\n",
       "      <td>[-0.06369742, -0.040109098, 0.06092408, -0.007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norway ..........................................</td>\n",
       "      <td>{\"format\": \"PDF 1.6\", \"title\": \"Regulation of ...</td>\n",
       "      <td>4</td>\n",
       "      <td>downloaded_pdf.pdf</td>\n",
       "      <td>[-0.038165003, -0.029677343, 0.06849071, 0.015...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  # Regulation of Artificial Intelligence in Sel...   \n",
       "1  This report is provided for reference purposes...   \n",
       "2  ### Contents\\n\\n**Comparative Summary ...........   \n",
       "3  Taiwan ..........................................   \n",
       "4  Norway ..........................................   \n",
       "\n",
       "                                            metadata  page_number  \\\n",
       "0  {\"format\": \"PDF 1.6\", \"title\": \"Regulation of ...            0   \n",
       "1  {\"format\": \"PDF 1.6\", \"title\": \"Regulation of ...            1   \n",
       "2  {\"format\": \"PDF 1.6\", \"title\": \"Regulation of ...            2   \n",
       "3  {\"format\": \"PDF 1.6\", \"title\": \"Regulation of ...            3   \n",
       "4  {\"format\": \"PDF 1.6\", \"title\": \"Regulation of ...            4   \n",
       "\n",
       "                title                                             vector  \n",
       "0  downloaded_pdf.pdf  [-0.016118292, 0.028076159, 0.04120163, 0.0225...  \n",
       "1  downloaded_pdf.pdf  [0.023184152, 0.033128623, 0.099621244, 0.0307...  \n",
       "2  downloaded_pdf.pdf  [-0.033615343, -0.013138391, 0.054029632, 0.03...  \n",
       "3  downloaded_pdf.pdf  [-0.06369742, -0.040109098, 0.06092408, -0.007...  \n",
       "4  downloaded_pdf.pdf  [-0.038165003, -0.029677343, 0.06849071, 0.015...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: \"\"What are the assets of the Reserve Bank of Australia?\"\"\n"
     ]
    }
   ],
   "source": [
    "import instructor\n",
    "import google.generativeai as genai\n",
    "from pydantic import BaseModel, Field\n",
    "import random\n",
    "\n",
    "# Initialize the Gemini client\n",
    "client = instructor.from_gemini(genai.GenerativeModel(\"gemini-1.5-flash-exp-0827\"))\n",
    "\n",
    "# Define the Pydantic model for the question-answer pair\n",
    "class QuestionAnswerPair(BaseModel):\n",
    "    question: str = Field(description=\"The generated question from the text chunk.\")\n",
    "    answer: str = Field(description=\"The answer to the generated question.\")\n",
    "\n",
    "# Sample text chunk (replace this with any random page or chunk of text)\n",
    "text_chunk = \"\"\"\n",
    "The Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia's central bank and banknote issuing authority, when the Reserve Bank Act 1959 removed the central banking functions from the Commonwealth Bank. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\n",
    "\"\"\"\n",
    "\n",
    "# Function to generate synthetic questions\n",
    "def generate_questions(chunk: str, num_questions: int = 5):\n",
    "    questions = []\n",
    "    for _ in range(num_questions):\n",
    "        response = client.create(\n",
    "            response_model=QuestionAnswerPair,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a world-class AI that excels at generating hypothetical search queries. \"\n",
    "                               \"You're about to be given a text snippet and asked to generate a search query \"\n",
    "                               \"which is specific to the text chunk you'll be given. Make sure to use information \"\n",
    "                               \"from the text chunk.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Here is the text chunk: {chunk}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        questions.append(response.question)\n",
    "    return questions\n",
    "\n",
    "# Generate and print synthetic questions\n",
    "synthetic_questions = generate_questions(text_chunk,num_questions=1)\n",
    "for i, question in enumerate(synthetic_questions, 1):\n",
    "    print(f\"Question {i}: {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pydantic model for the question-answer pair\n",
    "client = instructor.from_gemini(genai.GenerativeModel(\"gemini-1.5-flash-exp-0827\"))\n",
    "class QuestionReasonPair(BaseModel):\n",
    "    reasoning: str = Field(description=\"The step-by-step reasoning or chain of thought used to derive the answer.\")\n",
    "    question: str = Field(description=\"The generated question from the text chunk.\")\n",
    "\n",
    "\n",
    "@tenacity.retry(wait=tenacity.wait_fixed(5), stop=tenacity.stop_after_attempt(3))\n",
    "def generate_questions(chunk: str):\n",
    "    response = client.create(\n",
    "        response_model=QuestionReasonPair,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"<instructions>\"\n",
    "                           \"Given a text sample or chunk, you must generate a single query that accurately represents \"\n",
    "                           \"the main topic or information contained within the text. The query should be concise \"\n",
    "                           \"and relevant to the content of the text.\"\n",
    "                           \"</instructions>\"\n",
    "                           \"<important_instruction>\"\n",
    "                           \"Ensure the query is specific and captures the essence of the text. Avoid overly broad \"\n",
    "                           \"or vague queries.\"\n",
    "                           \"</important_instruction>\"\n",
    "                           \"<steps>\"\n",
    "                           \"<step>Read the text sample carefully to understand its main topic or information.</step>\"\n",
    "                           \"<step>Identify the key points or themes in the text.</step>\"\n",
    "                           \"<step>Formulate a chain of thought reasoning that leads to a query that encapsulates the main topic or key points of the text.</step>\"\n",
    "                           \"<step>Generate a question based on the chain of thought reasoning.</step>\"\n",
    "                           \"<step>Ensure the query is concise and relevant to the text.</step>\"\n",
    "                           \"</steps>\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"<text_sample>{chunk}</text_sample>\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = lancedb.connect(\"./.lancedb\")\n",
    "table = db.open_table(\"corpus\")\n",
    "df = table.to_pandas()\n",
    "random_row = df.sample(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generate_questions(random_row['text'].values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ The text discusses the initiatives of Kazakhstan, Latvia and Lithuania regarding the adoption and integration   │\n",
       "│ of AI within their economies and public sectors. The key initiatives in Kazakhstan include the establishment of │\n",
       "│ tech parks, development of AI infrastructure, and designation of research centers.  Latvia focused on AI        │\n",
       "│ integration in e-services, while Lithuania highlighted an innovation program that includes some AI elements. A  │\n",
       "│ question that encapsulates the main topic would be what are the key strategies and initiatives that these       │\n",
       "│ countries have for promoting the use of AI.                                                                     │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ The text discusses the initiatives of Kazakhstan, Latvia and Lithuania regarding the adoption and integration   │\n",
       "│ of AI within their economies and public sectors. The key initiatives in Kazakhstan include the establishment of │\n",
       "│ tech parks, development of AI infrastructure, and designation of research centers.  Latvia focused on AI        │\n",
       "│ integration in e-services, while Lithuania highlighted an innovation program that includes some AI elements. A  │\n",
       "│ question that encapsulates the main topic would be what are the key strategies and initiatives that these       │\n",
       "│ countries have for promoting the use of AI.                                                                     │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ What are the key initiatives and strategies implemented by Kazakhstan and Baltic countries (Latvia and          │\n",
       "│ Lithuania) to promote and integrate Artificial Intelligence (AI) within their respective economies and public   │\n",
       "│ sectors?                                                                                                        │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ What are the key initiatives and strategies implemented by Kazakhstan and Baltic countries (Latvia and          │\n",
       "│ Lithuania) to promote and integrate Artificial Intelligence (AI) within their respective economies and public   │\n",
       "│ sectors?                                                                                                        │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use panel and console and then print the output\n",
    "console = Console()\n",
    "console.print(Panel(output.reasoning))\n",
    "console.print(Panel(output.question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [01:25<03:39,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate question after multiple retries: RetryError[<Future at 0x32717bed0 state=finished raised InstructorRetryException>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [04:24<01:13,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate question after multiple retries: RetryError[<Future at 0x327360550 state=finished raised InstructorRetryException>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:52<00:00,  7.04s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_of_questions = 50\n",
    "questions = []\n",
    "for i in tqdm(range(num_of_questions)):\n",
    "    random_row = df.sample(1)\n",
    "    try:\n",
    "        output = generate_questions(random_row['text'].values[0])\n",
    "        questions.append({\"question\": output.question,\n",
    "                        \"reasoning\": output.reasoning, \n",
    "                        \"page_number\": random_row['page_number'].values[0]})\n",
    "    except tenacity.RetryError as e:\n",
    "        print(f\"Failed to generate question after multiple retries: {e}\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this df to a table\n",
    "pd.DataFrame(questions).to_csv('questions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv('questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>page_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does China's AI development benefit from i...</td>\n",
       "      <td>The text discusses how Chinese AI companies ut...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the key goals and initiatives of the ...</td>\n",
       "      <td>The text discusses the Declaration of Cooperat...</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the key initiatives and strategies im...</td>\n",
       "      <td>The text focuses on Germany's digital agenda a...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the key proposals and initiatives out...</td>\n",
       "      <td>The text sample focuses on Russia's approach t...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the countries included in the Europe ...</td>\n",
       "      <td>The provided text sample lists various countri...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How does China's AI development benefit from i...   \n",
       "1  What are the key goals and initiatives of the ...   \n",
       "2  What are the key initiatives and strategies im...   \n",
       "3  What are the key proposals and initiatives out...   \n",
       "4  What are the countries included in the Europe ...   \n",
       "\n",
       "                                           reasoning  page_number  \n",
       "0  The text discusses how Chinese AI companies ut...          137  \n",
       "1  The text discusses the Declaration of Cooperat...           71  \n",
       "2  The text focuses on Germany's digital agenda a...           89  \n",
       "3  The text sample focuses on Russia's approach t...          108  \n",
       "4  The provided text sample lists various countri...            3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_by_tokens(text, max_token_length=100, overlap=0):\n",
    "    enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "    tokens = enc.encode(text,disallowed_special=())\n",
    "    chunks = []\n",
    "\n",
    "    for i in range(0, len(tokens), max_token_length - overlap):\n",
    "        chunk_tokens = tokens[i:i + max_token_length]\n",
    "        chunk_text = enc.decode(chunk_tokens)\n",
    "        chunks.append(chunk_text)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    page_number = row['page_number']\n",
    "    text_chunks = chunk_text_by_tokens(text,max_token_length=800,overlap=400)\n",
    "    for text_chunk in text_chunks:\n",
    "        final_list.append({'text': text_chunk, 'page_number': page_number})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIEmbeddings(name='text-embedding-3-small')\n",
    "# Define the LanceModel for your table\n",
    "class Corpus(LanceModel):\n",
    "    text: str = model.SourceField()  \n",
    "    page_number: int = None  \n",
    "    vector: Vector(1536) = model.VectorField()\n",
    "\n",
    "# Create the table\n",
    "db = lancedb.connect(\"./.lancedb\")\n",
    "tbl = db.create_table(\"eval_corpus\", schema=Corpus)\n",
    "tbl.add(final_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.create_fts_index(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to calculate MRR\n",
    "def mean_reciprocal_rank(results, relevant_indices):\n",
    "    reciprocal_ranks = []\n",
    "    for result, relevant in zip(results, relevant_indices):\n",
    "        for rank, doc in enumerate(result, start=1):\n",
    "            if doc in relevant:\n",
    "                reciprocal_ranks.append(1 / rank)\n",
    "                break\n",
    "        else:\n",
    "            reciprocal_ranks.append(0)\n",
    "    return np.mean(reciprocal_ranks)\n",
    "\n",
    "# Define a function to calculate Recall@K\n",
    "def recall_at_k(results, relevant_indices, k):\n",
    "    recalls = []\n",
    "    for result, relevant in zip(results, relevant_indices):\n",
    "        relevant_set = set(relevant)\n",
    "        retrieved_set = set(result[:k])\n",
    "        recalls.append(len(relevant_set & retrieved_set) / len(relevant_set))\n",
    "    return np.mean(recalls)\n",
    "\n",
    "# Manual implementation of DCG (Discounted Cumulative Gain)\n",
    "def dcg_at_k(relevance_scores, k):\n",
    "    relevance_scores = np.asfarray(relevance_scores)[:k]\n",
    "    if relevance_scores.size:\n",
    "        return relevance_scores[0] + np.sum(relevance_scores[1:] / np.log2(np.arange(2, relevance_scores.size + 1)))\n",
    "    return 0.\n",
    "\n",
    "# Manual implementation of NDCG (Normalized Discounted Cumulative Gain)\n",
    "def ndcg_at_k(results, relevant_indices, k):\n",
    "    ndcg_scores = []\n",
    "    for result, relevant in zip(results, relevant_indices):\n",
    "        relevance = [1 if doc in relevant else 0 for doc in result[:k]]\n",
    "        dcg = dcg_at_k(relevance, k)\n",
    "        ideal_relevance = sorted(relevance, reverse=True)\n",
    "        idcg = dcg_at_k(ideal_relevance, k)\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0\n",
    "        ndcg_scores.append(ndcg)\n",
    "    return np.mean(ndcg_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_search(tbl, df_questions, query_types=['fts', 'vector', 'hybrid']):\n",
    "    metrics_list = []\n",
    "    \n",
    "    for query_type in query_types:\n",
    "        print(f\"Evaluating {query_type} search...\")\n",
    "        mrr_scores, ndcg_scores, recall_scores = [], [], []\n",
    "        \n",
    "        for index, row in df_questions.iterrows():\n",
    "            query = row['question']\n",
    "            page_number = row['page_number']\n",
    "            \n",
    "            search_results = tbl.search(query, query_type=query_type).limit(10).to_list()\n",
    "            retrieved_pages = [result['page_number'] for result in search_results]\n",
    "            relevant_pages = [page_number]\n",
    "            \n",
    "            mrr = mean_reciprocal_rank([retrieved_pages], [relevant_pages])\n",
    "            ndcg = ndcg_at_k([retrieved_pages], [relevant_pages], k=10)\n",
    "            recall = recall_at_k([retrieved_pages], [relevant_pages], k=10)\n",
    "            \n",
    "            mrr_scores.append(mrr)\n",
    "            ndcg_scores.append(ndcg)\n",
    "            recall_scores.append(recall)\n",
    "            \n",
    "            metrics_list.append({\n",
    "                'method': query_type,\n",
    "                'question': query,\n",
    "                'page_number': page_number,\n",
    "                'MRR': mrr,\n",
    "                'NDCG@10': ndcg,\n",
    "                'Recall@10': recall\n",
    "            })\n",
    "        \n",
    "        avg_mrr = np.mean(mrr_scores)\n",
    "        avg_ndcg = np.mean(ndcg_scores)\n",
    "        avg_recall = np.mean(recall_scores)\n",
    "        \n",
    "        print(f\"Average MRR: {avg_mrr:.4f}\")\n",
    "        print(f\"Average NDCG@10: {avg_ndcg:.4f}\")\n",
    "        print(f\"Average Recall@10: {avg_recall:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    return pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fts search...\n",
      "Average MRR: 0.7730\n",
      "Average NDCG@10: 0.7833\n",
      "Average Recall@10: 0.9000\n",
      "\n",
      "Evaluating vector search...\n",
      "Average MRR: 0.9467\n",
      "Average NDCG@10: 0.8810\n",
      "Average Recall@10: 0.9800\n",
      "\n",
      "Evaluating hybrid search...\n",
      "Average MRR: 0.9367\n",
      "Average NDCG@10: 0.8696\n",
      "Average Recall@10: 0.9800\n",
      "\n",
      "  method                                           question  page_number  MRR  \\\n",
      "0    fts  How does China's AI development benefit from i...          137  1.0   \n",
      "1    fts  What are the key goals and initiatives of the ...           71  1.0   \n",
      "2    fts  What are the key initiatives and strategies im...           89  1.0   \n",
      "3    fts  What are the key proposals and initiatives out...          108  1.0   \n",
      "4    fts  What are the countries included in the Europe ...            3  1.0   \n",
      "\n",
      "    NDCG@10  Recall@10  \n",
      "0  1.000000        1.0  \n",
      "1  1.000000        1.0  \n",
      "2  0.678104        1.0  \n",
      "3  1.000000        1.0  \n",
      "4  1.000000        1.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run the evaluation\n",
    "results_df = evaluate_search(tbl, df_questions)\n",
    "\n",
    "# Display the first few rows of the results\n",
    "print(results_df.head())\n",
    "\n",
    "# Optional: Save the results to a CSV file\n",
    "results_df.to_csv('search_evaluation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-bert-implementation:\n",
      "- configuration_bert.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-bert-implementation:\n",
      "- modeling_bert.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    }
   ],
   "source": [
    "rag = RAGPretrainedModel.from_pretrained(\"jinaai/jina-colbert-v1-en\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/a0/4c/a04cd86fe01b157b8cc5a51615eef5d3e9dce42c5569c2b74b15f66522dbba90/3f58890b1dfdfec066ef12ba431fa9d56992da9e30a53489242c4156e37e9017?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1726898591&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNjg5ODU5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9hMC80Yy9hMDRjZDg2ZmUwMWIxNTdiOGNjNWE1MTYxNWVlZjVkM2U5ZGNlNDJjNTU2OWMyYjc0YjE1ZjY2NTIyZGJiYTkwLzNmNTg4OTBiMWRmZGZlYzA2NmVmMTJiYTQzMWZhOWQ1Njk5MmRhOWUzMGE1MzQ4OTI0MmM0MTU2ZTM3ZTkwMTc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Dp8dlDh0ALbaOuy2JdI0cL09gKhwoR7sEorZIjgQfoUR-7VQz%7Ev6k0nyJr6WmoJCqWKMtN3n711g93%7EfF15yU3yj5DA%7EsrYCSGl2uX8tuxW4GmXdQxMdCo5p5RTgZcXUJ88agFfld3yrY9vYDQ9CoQ2JmIlIYO8OkTsbgsW5fpvt5WS1DyzaEJ6O9lXiETVCt2f3LsLjngFX6b1cnAYwWKC5DOplHVHftrMEdnh9amakuUarHqKR04ImGSSU79XaDBssTXqEROy4CFg7XrAKrW%7ETMh1uYa%7EYUDQ6pxjfXmmPvgDXIOkrjliqSzoQr5M9YU0PvbERt0BsmY6cisXCog__&Key-Pair-Id=K3ESJI6DHPFC7: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rag = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "def create_ragatouille_index(final_list, index_name=\"ragatouille_index\", model=\"answerdotai/answerai-colbert-small-v1\"):\n",
    "    rag = RAGPretrainedModel.from_pretrained(model)\n",
    "    \n",
    "    # Create a list of documents with their text content\n",
    "    docs = [item['text'] for item in final_list]\n",
    "    \n",
    "    # Create separate lists for document IDs and metadata\n",
    "    doc_ids = [f\"doc_{i}\" for i in range(len(docs))]\n",
    "    doc_metadata = [{'page_number': item['page_number']} for item in final_list]\n",
    "    \n",
    "    rag.index(\n",
    "        collection=docs,\n",
    "        document_ids=doc_ids,\n",
    "        document_metadatas=doc_metadata,\n",
    "        index_name=index_name,\n",
    "        max_document_length=512,\n",
    "        split_documents=False,  # We've already split the documents\n",
    "    )\n",
    "    return rag\n",
    "\n",
    "# Create the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Sep 17, 23:18:22] #> Creating directory .ragatouille/colbert/indexes/rag_model_answerdotai \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:18:23] [0] \t\t #> Encoding 422 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "100%|██████████| 14/14 [00:19<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:18:43] [0] \t\t avg_doclen_est = 277.8104248046875 \t len(local_sample) = 422\n",
      "[Sep 17, 23:18:43] [0] \t\t Creating 4,096 partitions.\n",
      "[Sep 17, 23:18:43] [0] \t\t *Estimated* 117,235 embeddings.\n",
      "[Sep 17, 23:18:43] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/rag_model_answerdotai/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/colbert/indexing/collection_indexer.py:256: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sub_sample = torch.load(sub_sample_path)\n",
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  centroids = torch.load(centroids_path, map_location='cpu')\n",
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_residual = torch.load(avgresidual_path, map_location='cpu')\n",
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used 20 iterations (29.2793s) to cluster 111375 items into 4096 clusters\n",
      "[0.016, 0.016, 0.014, 0.015, 0.014, 0.015, 0.015, 0.016, 0.015, 0.015, 0.014, 0.016, 0.015, 0.016, 0.015, 0.016, 0.014, 0.017, 0.015, 0.014, 0.014, 0.015, 0.016, 0.015, 0.015, 0.015, 0.015, 0.015, 0.016, 0.015, 0.014, 0.014, 0.015, 0.016, 0.015, 0.016, 0.016, 0.015, 0.015, 0.016, 0.016, 0.017, 0.016, 0.015, 0.015, 0.016, 0.017, 0.015, 0.014, 0.017, 0.017, 0.016, 0.016, 0.015, 0.015, 0.015, 0.016, 0.015, 0.015, 0.016, 0.014, 0.015, 0.016, 0.015, 0.016, 0.017, 0.017, 0.014, 0.015, 0.015, 0.016, 0.015, 0.015, 0.015, 0.016, 0.016, 0.015, 0.014, 0.015, 0.017, 0.015, 0.015, 0.016, 0.014, 0.015, 0.017, 0.014, 0.015, 0.016, 0.016, 0.014, 0.016, 0.015, 0.018, 0.015, 0.015]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:19:13] [0] \t\t #> Encoding 422 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 14/14 [00:19<00:00,  1.40s/it]\n",
      "1it [00:20, 20.42s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(codes_path, map_location='cpu')\n",
      "100%|██████████| 1/1 [00:00<00:00, 877.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:19:33] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Sep 17, 23:19:33] #> Building the emb2pid mapping..\n",
      "[Sep 17, 23:19:33] len(emb2pid) = 117236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4096/4096 [00:00<00:00, 147263.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:19:33] #> Saved optimized IVF to .ragatouille/colbert/indexes/rag_model_answerdotai/ivf.pid.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done indexing!\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Sep 17, 23:19:39] #> Creating directory .ragatouille/colbert/indexes/rag_model_jina \n",
      "\n",
      "\n",
      "[Sep 17, 23:19:44] [0] \t\t #> Encoding 422 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:34<00:00,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:21:18] [0] \t\t avg_doclen_est = 277.8104248046875 \t len(local_sample) = 422\n",
      "[Sep 17, 23:21:18] [0] \t\t Creating 4,096 partitions.\n",
      "[Sep 17, 23:21:18] [0] \t\t *Estimated* 117,235 embeddings.\n",
      "[Sep 17, 23:21:18] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/rag_model_jina/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used 20 iterations (29.1274s) to cluster 111375 items into 4096 clusters\n",
      "[0.032, 0.032, 0.033, 0.034, 0.031, 0.03, 0.03, 0.033, 0.033, 0.031, 0.033, 0.032, 0.029, 0.031, 0.033, 0.034, 0.032, 0.031, 0.032, 0.033, 0.033, 0.03, 0.03, 0.03, 0.033, 0.031, 0.034, 0.033, 0.029, 0.034, 0.032, 0.031, 0.032, 0.029, 0.031, 0.03, 0.031, 0.031, 0.032, 0.031, 0.03, 0.031, 0.031, 0.031, 0.029, 0.035, 0.03, 0.033, 0.031, 0.033, 0.034, 0.032, 0.03, 0.031, 0.034, 0.033, 0.035, 0.031, 0.03, 0.032, 0.032, 0.031, 0.032, 0.031, 0.031, 0.033, 0.032, 0.03, 0.031, 0.032, 0.032, 0.031, 0.033, 0.031, 0.03, 0.031, 0.032, 0.031, 0.031, 0.033, 0.032, 0.031, 0.029, 0.034, 0.031, 0.032, 0.031, 0.037, 0.034, 0.031, 0.034, 0.034, 0.032, 0.029, 0.03, 0.033, 0.03, 0.031, 0.033, 0.036, 0.034, 0.032, 0.031, 0.033, 0.03, 0.03, 0.035, 0.03, 0.031, 0.031, 0.033, 0.032, 0.031, 0.033, 0.029, 0.034, 0.032, 0.031, 0.03, 0.032, 0.032, 0.033, 0.029, 0.031, 0.031, 0.033, 0.029, 0.03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:21:48] [0] \t\t #> Encoding 422 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 14/14 [01:31<00:00,  6.52s/it]\n",
      "1it [01:32, 92.04s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 924.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:23:20] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Sep 17, 23:23:20] #> Building the emb2pid mapping..\n",
      "[Sep 17, 23:23:20] len(emb2pid) = 117236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4096/4096 [00:00<00:00, 143698.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:23:20] #> Saved optimized IVF to .ragatouille/colbert/indexes/rag_model_jina/ivf.pid.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done indexing!\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Sep 17, 23:23:21] #> Creating directory .ragatouille/colbert/indexes/rag_model_colbert_v2 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:23:22] [0] \t\t #> Encoding 422 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:52<00:00,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:24:15] [0] \t\t avg_doclen_est = 277.8104248046875 \t len(local_sample) = 422\n",
      "[Sep 17, 23:24:15] [0] \t\t Creating 4,096 partitions.\n",
      "[Sep 17, 23:24:15] [0] \t\t *Estimated* 117,235 embeddings.\n",
      "[Sep 17, 23:24:15] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/rag_model_colbert_v2/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used 20 iterations (17.9892s) to cluster 111375 items into 4096 clusters\n",
      "[0.03, 0.03, 0.034, 0.03, 0.029, 0.033, 0.029, 0.028, 0.029, 0.035, 0.028, 0.03, 0.031, 0.03, 0.029, 0.029, 0.03, 0.03, 0.029, 0.032, 0.033, 0.031, 0.03, 0.032, 0.028, 0.029, 0.032, 0.031, 0.029, 0.034, 0.029, 0.033, 0.031, 0.029, 0.03, 0.029, 0.031, 0.031, 0.029, 0.035, 0.03, 0.031, 0.031, 0.028, 0.03, 0.028, 0.031, 0.032, 0.032, 0.029, 0.028, 0.03, 0.032, 0.029, 0.031, 0.032, 0.035, 0.031, 0.037, 0.029, 0.029, 0.032, 0.031, 0.031, 0.03, 0.03, 0.032, 0.031, 0.028, 0.032, 0.031, 0.029, 0.031, 0.031, 0.029, 0.03, 0.031, 0.03, 0.034, 0.032, 0.035, 0.03, 0.032, 0.03, 0.03, 0.029, 0.031, 0.033, 0.029, 0.034, 0.03, 0.033, 0.031, 0.031, 0.031, 0.031, 0.033, 0.029, 0.03, 0.031, 0.032, 0.034, 0.03, 0.032, 0.031, 0.028, 0.03, 0.03, 0.03, 0.028, 0.032, 0.031, 0.034, 0.028, 0.031, 0.029, 0.03, 0.033, 0.031, 0.032, 0.029, 0.03, 0.029, 0.032, 0.027, 0.034, 0.031, 0.03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:24:33] [0] \t\t #> Encoding 422 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 14/14 [00:52<00:00,  3.73s/it]\n",
      "1it [00:53, 53.07s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1281.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:25:26] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Sep 17, 23:25:26] #> Building the emb2pid mapping..\n",
      "[Sep 17, 23:25:26] len(emb2pid) = 117236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4096/4096 [00:00<00:00, 150206.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:25:26] #> Saved optimized IVF to .ragatouille/colbert/indexes/rag_model_colbert_v2/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rag_model_answerdotai = create_ragatouille_index(final_list, model=\"answerdotai/answerai-colbert-small-v1\",index_name=\"rag_model_answerdotai\")\n",
    "rag_model_jina = create_ragatouille_index(final_list, model=\"jinaai/jina-colbert-v1-en\",index_name=\"rag_model_jina\")\n",
    "rag_model_colbert_v2 = create_ragatouille_index(final_list, model=\"colbert-ir/colbertv2.0\",index_name=\"rag_model_colbert_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ragatouille_search(rag_model, df_questions, model, k=10):\n",
    "    metrics_list = []\n",
    "    mrr_scores, ndcg_scores, recall_scores = [], [], []\n",
    "    \n",
    "    for index, row in df_questions.iterrows():\n",
    "        query = row['question']\n",
    "        actual_page_number = row['page_number']\n",
    "        \n",
    "        search_results = rag_model.search(query, k=k)\n",
    "        # print(search_results)\n",
    "        retrieved_pages = [result['document_metadata']['page_number'] for result in search_results]\n",
    "        relevant_pages = [actual_page_number]\n",
    "        \n",
    "        mrr = mean_reciprocal_rank([retrieved_pages], [relevant_pages])\n",
    "        ndcg = ndcg_at_k([retrieved_pages], [relevant_pages], k=k)\n",
    "        recall = recall_at_k([retrieved_pages], [relevant_pages], k=k)\n",
    "        \n",
    "        mrr_scores.append(mrr)\n",
    "        ndcg_scores.append(ndcg)\n",
    "        recall_scores.append(recall)\n",
    "        \n",
    "        metrics_list.append({\n",
    "            'method': f'ragatouille_{model}',\n",
    "            'question': query,\n",
    "            'page_number': actual_page_number,\n",
    "            'MRR': mrr,\n",
    "            'NDCG@10': ndcg,\n",
    "            'Recall@10': recall\n",
    "        })\n",
    "    \n",
    "    avg_mrr = np.mean(mrr_scores)\n",
    "    avg_ndcg = np.mean(ndcg_scores)\n",
    "    avg_recall = np.mean(recall_scores)\n",
    "    \n",
    "    print(f\"Ragatouille Search Results for model {model}:\")\n",
    "    print(f\"Average MRR: {avg_mrr:.4f}\")\n",
    "    print(f\"Average NDCG@10: {avg_ndcg:.4f}\")\n",
    "    print(f\"Average Recall@10: {avg_recall:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(metrics_list)\n",
    "\n",
    "# Run the evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index rag_model_answerdotai for the first time... This may take a few seconds\n",
      "[Sep 17, 23:25:28] #> Loading codec...\n",
      "[Sep 17, 23:25:28] #> Loading IVF...\n",
      "[Sep 17, 23:25:28] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/colbert/search/index_loader.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ivf, ivf_lengths = torch.load(os.path.join(self.index_path, \"ivf.pid.pt\"), map_location='cpu')\n",
      "100%|██████████| 1/1 [00:00<00:00, 2462.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:25:28] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/jshah/micromamba/envs/hack/lib/python3.11/site-packages/colbert/indexing/codecs/residual_embeddings.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(residuals_path, map_location='cpu')\n",
      "100%|██████████| 1/1 [00:00<00:00, 180.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . How does China's AI development benefit from its partnerships with African nations, particularly Zimbabwe, in terms of data and technological advancement?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2129,  2515,  2859,  1005,  1055,  9932,  2458,  5770,\n",
      "         2013,  2049, 13797,  2007,  3060,  3741,  1010,  3391, 11399,  1010,\n",
      "         1999,  3408,  1997,  2951,  1998, 10660, 12607,  1029,   102,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragatouille Search Results for model answerdotai_colbert_small:\n",
      "Average MRR: 0.8933\n",
      "Average NDCG@10: 0.8630\n",
      "Average Recall@10: 0.9600\n",
      "Loading searcher for index rag_model_jina for the first time... This may take a few seconds\n",
      "[Sep 17, 23:25:34] #> Loading codec...\n",
      "[Sep 17, 23:25:34] #> Loading IVF...\n",
      "[Sep 17, 23:25:34] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1940.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:25:34] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 218.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . How does China's AI development benefit from its partnerships with African nations, particularly Zimbabwe, in terms of data and technological advancement?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2129,  2515,  2859,  1005,  1055,  9932,  2458,  5770,\n",
      "         2013,  2049, 13797,  2007,  3060,  3741,  1010,  3391, 11399,  1010,\n",
      "         1999,  3408,  1997,  2951,  1998, 10660, 12607,  1029,   102,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragatouille Search Results for model jinaa_colbert_v1_en:\n",
      "Average MRR: 0.8950\n",
      "Average NDCG@10: 0.8915\n",
      "Average Recall@10: 0.9800\n",
      "Loading searcher for index rag_model_colbert_v2 for the first time... This may take a few seconds\n",
      "[Sep 17, 23:25:37] #> Loading codec...\n",
      "[Sep 17, 23:25:37] #> Loading IVF...\n",
      "[Sep 17, 23:25:37] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5084.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sep 17, 23:25:37] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 158.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . How does China's AI development benefit from its partnerships with African nations, particularly Zimbabwe, in terms of data and technological advancement?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2129,  2515,  2859,  1005,  1055,  9932,  2458,  5770,\n",
      "         2013,  2049, 13797,  2007,  3060,  3741,  1010,  3391, 11399,  1010,\n",
      "         1999,  3408,  1997,  2951,  1998, 10660, 12607,  1029,   102,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragatouille Search Results for model colbert_v2.0:\n",
      "Average MRR: 0.8902\n",
      "Average NDCG@10: 0.9032\n",
      "Average Recall@10: 1.0000\n",
      "                                  method  \\\n",
      "0  ragatouille_answerdotai_colbert_small   \n",
      "1  ragatouille_answerdotai_colbert_small   \n",
      "2  ragatouille_answerdotai_colbert_small   \n",
      "3  ragatouille_answerdotai_colbert_small   \n",
      "4  ragatouille_answerdotai_colbert_small   \n",
      "\n",
      "                                            question  page_number       MRR  \\\n",
      "0  How does China's AI development benefit from i...          137  1.000000   \n",
      "1  What are the key goals and initiatives of the ...           71  1.000000   \n",
      "2  What are the key initiatives and strategies im...           89  1.000000   \n",
      "3  What are the key proposals and initiatives out...          108  1.000000   \n",
      "4  What are the countries included in the Europe ...            3  0.333333   \n",
      "\n",
      "    NDCG@10  Recall@10  \n",
      "0  1.000000        1.0  \n",
      "1  1.000000        1.0  \n",
      "2  0.815465        1.0  \n",
      "3  1.000000        1.0  \n",
      "4  0.630930        1.0  \n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation for both rag_models\n",
    "ragatouille_results_model_1 = evaluate_ragatouille_search(rag_model_answerdotai, df_questions, model='answerdotai_colbert_small')\n",
    "ragatouille_results_model_2 = evaluate_ragatouille_search(rag_model_jina, df_questions, model='jinaa_colbert_v1_en')\n",
    "ragatouille_results_model_3 = evaluate_ragatouille_search(rag_model_colbert_v2, df_questions, model='colbert_v2.0')\n",
    "\n",
    "# Combine the results from both models\n",
    "combined_results = pd.concat([ragatouille_results_model_1, ragatouille_results_model_2, ragatouille_results_model_3])\n",
    "\n",
    "# Display the first few rows of the combined results\n",
    "print(combined_results.head())\n",
    "\n",
    "# Optional: Save the combined results to a CSV file\n",
    "combined_results.to_csv('ragatouille_evaluation_results_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
